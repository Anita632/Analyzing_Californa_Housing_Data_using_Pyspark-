{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Analyzing california housing  data using Pyspark SQL"
      ],
      "metadata": {
        "id": "hOJ_n-OVmE9Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFRqFTI8kUX5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, avg, max, min\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import floor\n",
        "from pyspark.sql.functions import when"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"California Housing Analysis\").getOrCreate()"
      ],
      "metadata": {
        "id": "YFH2GnKqkm3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('/content/sample_data/california_housing_train.csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "zRD5cjDUlPsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrEcxaLfldWY",
        "outputId": "b1ea6ed0-254f-4256-ae9f-c1ca5edf3cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -122.05|   37.37|              27.0|     3885.0|         661.0|    1537.0|     606.0|       6.6085|          344700.0|\n",
            "|   -118.3|   34.26|              43.0|     1510.0|         310.0|     809.0|     277.0|        3.599|          176500.0|\n",
            "|  -117.81|   33.78|              27.0|     3589.0|         507.0|    1484.0|     495.0|       5.7934|          270500.0|\n",
            "|  -118.36|   33.82|              28.0|       67.0|          15.0|      49.0|      11.0|       6.1359|          330000.0|\n",
            "|  -119.67|   36.33|              19.0|     1241.0|         244.0|     850.0|     237.0|       2.9375|           81700.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b489859"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8346b67f"
      },
      "source": [
        "## Problem statement 1: Find the top regions or neighborhoods by median house value.\n",
        "\n",
        "### Subtask:\n",
        "Group by a suitable spatial identifier (longitude/latitude bins or a combination) and calculate the median house value for each.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dc2a2d8"
      },
      "source": [
        "**Reasoning**:\n",
        "Create spatial bins using longitude and latitude, then group by these bins and calculate the median house value for each bin. Order the results and show the top ones.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "041680d7",
        "outputId": "c7badafe-1fd5-4dde-8741-ce608cdfa11c"
      },
      "source": [
        "\n",
        "# Create spatial bins\n",
        "df_binned = df.withColumn(\"longitude_bin\", floor(col(\"longitude\") * 10) / 10)\n",
        "df_binned = df_binned.withColumn(\"latitude_bin\", floor(col(\"latitude\") * 10) / 10)\n",
        "df_binned = df_binned.withColumn(\"spatial_id\", F.concat(col(\"longitude_bin\"), F.lit(\"_\"), col(\"latitude_bin\")))\n",
        "\n",
        "# Group by spatial ID and calculate median house value\n",
        "median_house_value_by_spatial_id = df_binned.groupBy(\"spatial_id\") \\\n",
        "    .agg(F.expr(\"percentile_approx(median_house_value, 0.5)\").alias(\"median_house_value\")) \\\n",
        "    .orderBy(F.desc(\"median_house_value\"))\n",
        "\n",
        "# Show top regions\n",
        "median_house_value_by_spatial_id.show(10, truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+\n",
            "|spatial_id |median_house_value|\n",
            "+-----------+------------------+\n",
            "|-120.1_34.7|500001.0          |\n",
            "|-118.9_34.0|500001.0          |\n",
            "|-118.5_33.7|500001.0          |\n",
            "|-117.4_33.5|500001.0          |\n",
            "|-118.5_33.8|500001.0          |\n",
            "|-117.9_33.5|500001.0          |\n",
            "|-118.6_34.0|500001.0          |\n",
            "|-118.0_33.5|500001.0          |\n",
            "|-118.7_34.0|500001.0          |\n",
            "|-117.7_33.3|500001.0          |\n",
            "+-----------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9e38b8c"
      },
      "source": [
        "## Problem statement 2: Analyze the distribution of median income by housing age bucket.\n",
        "\n",
        "### Subtask:\n",
        "Analyze the distribution of median income by housing age bucket.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7a28b6b"
      },
      "source": [
        "**Reasoning**:\n",
        "Define age buckets, create a new column for these buckets, group by these buckets, calculate descriptive statistics for median income within each bucket, and display the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4bfc3bd",
        "outputId": "1427e2af-fc0a-4ddf-c08c-d54d5e778252"
      },
      "source": [
        "# Define housing age bucket boundaries\n",
        "age_buckets = [0, 10, 20, 30, 40, 50, float('inf')]\n",
        "bucket_labels = ['0-9', '10-19', '20-29', '30-39', '40-49', '50+']\n",
        "\n",
        "# Create a new column for housing age buckets\n",
        "df_age_bucket = df.withColumn(\"housing_age_bucket\", when(col(\"housing_median_age\") < age_buckets[1], bucket_labels[0])\n",
        "      .when((col(\"housing_median_age\") >= age_buckets[1]) & (col(\"housing_median_age\") < age_buckets[2]), bucket_labels[1])\n",
        "      .when((col(\"housing_median_age\") >= age_buckets[2]) & (col(\"housing_median_age\") < age_buckets[3]), bucket_labels[2])\n",
        "      .when((col(\"housing_median_age\") >= age_buckets[3]) & (col(\"housing_median_age\") < age_buckets[4]), bucket_labels[3])\n",
        "      .when((col(\"housing_median_age\") >= age_buckets[4]) & (col(\"housing_median_age\") < age_buckets[5]), bucket_labels[4])\n",
        "      .otherwise(bucket_labels[5]))\n",
        "\n",
        "# Group by housing age bucket and calculate descriptive statistics for median income\n",
        "income_distribution_by_age = df_age_bucket.groupBy(\"housing_age_bucket\") \\\n",
        "    .agg(\n",
        "        F.count(\"median_income\").alias(\"count\"),\n",
        "        F.mean(\"median_income\").alias(\"mean_median_income\"),\n",
        "        F.stddev(\"median_income\").alias(\"stddev_median_income\"),\n",
        "        F.min(\"median_income\").alias(\"min_median_income\"),\n",
        "        F.max(\"median_income\").alias(\"max_median_income\")\n",
        "    ) \\\n",
        "    .orderBy(\"housing_age_bucket\") # Order by bucket label for better readability\n",
        "\n",
        "# Show the results\n",
        "income_distribution_by_age.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+-----+------------------+--------------------+-----------------+-----------------+\n",
            "|housing_age_bucket|count|mean_median_income|stddev_median_income|min_median_income|max_median_income|\n",
            "+------------------+-----+------------------+--------------------+-----------------+-----------------+\n",
            "|               0-9| 1087| 4.658022263109468|  1.9550809450541542|            0.536|          14.9009|\n",
            "|             10-19| 3739| 4.047213372559506|   1.860644548992904|           0.4999|          15.0001|\n",
            "|             20-29| 3985| 3.905507754077801|   1.937360148400664|           0.4999|          15.0001|\n",
            "|             30-39| 4770|3.7767662473794585|  1.7762026318205326|           0.4999|          15.0001|\n",
            "|             40-49| 2223|3.4151897435897465|   1.788978402791753|           0.4999|          15.0001|\n",
            "|               50+| 1196|3.8916693143812715|  2.3134548617834523|           0.4999|          15.0001|\n",
            "+------------------+-----+------------------+--------------------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c94fa8e8"
      },
      "source": [
        "## Problem statement 3: Examine the correlation between income and house value using income buckets.\n",
        "\n",
        "### Subtask:\n",
        "Create income buckets and then calculate the correlation between median income and median house value within each bucket.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "593be31e"
      },
      "source": [
        "**Reasoning**:\n",
        "Create income buckets and calculate the correlation between median income and median house value within each bucket.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb61c8ba",
        "outputId": "a62b34da-8f18-479f-8dec-350c0b195af0"
      },
      "source": [
        "from pyspark.sql.functions import expr\n",
        "\n",
        "# Define income bucket boundaries and labels\n",
        "income_buckets = [0, 1.5, 3.0, 4.5, 6.0, float('inf')]\n",
        "income_labels = ['0-1.5', '1.5-3.0', '3.0-4.5', '4.5-6.0', '6.0+']\n",
        "\n",
        "# Create a new column for income buckets\n",
        "df_income_bucket = df.withColumn(\"income_bucket\", when(col(\"median_income\") < income_buckets[1], income_labels[0])\n",
        "      .when((col(\"median_income\") >= income_buckets[1]) & (col(\"median_income\") < income_buckets[2]), income_labels[1])\n",
        "      .when((col(\"median_income\") >= income_buckets[2]) & (col(\"median_income\") < income_buckets[3]), income_labels[2])\n",
        "      .when((col(\"median_income\") >= income_buckets[3]) & (col(\"median_income\") < income_buckets[4]), income_labels[3])\n",
        "      .otherwise(income_labels[4]))\n",
        "\n",
        "# Group by income bucket and calculate the correlation between median_income and median_house_value\n",
        "correlation_by_income_bucket = df_income_bucket.groupBy(\"income_bucket\") \\\n",
        "    .agg(expr(\"corr(median_income, median_house_value)\").alias(\"correlation\")) \\\n",
        "    .orderBy(\"income_bucket\") # Order by bucket label for better readability\n",
        "\n",
        "# Display the correlation values for each income bucket\n",
        "correlation_by_income_bucket.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------------+\n",
            "|income_bucket|         correlation|\n",
            "+-------------+--------------------+\n",
            "|        0-1.5|-0.14852482255387112|\n",
            "|      1.5-3.0|  0.2634667954182644|\n",
            "|      3.0-4.5| 0.18512055212459216|\n",
            "|      4.5-6.0| 0.21884442888469297|\n",
            "|         6.0+|  0.5323338757403461|\n",
            "+-------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "947f3b2d"
      },
      "source": [
        "## Problem statement 4 : Identify outliers in the “rooms per household” ratio.\n",
        "\n",
        "### Subtask:\n",
        "Identify outliers in the “rooms per household” ratio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2a38493"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the 'rooms per household' ratio, its mean and standard deviation, and then identify outliers using the z-score method. Finally, display the relevant columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82bb496c",
        "outputId": "31cf42c2-2ee4-441b-e939-3d1e5e7aceb7"
      },
      "source": [
        "from pyspark.sql.functions import col, when, abs, mean, stddev\n",
        "\n",
        "# Calculate 'rooms per household' ratio\n",
        "df_rooms_per_household = df.withColumn(\"rooms_per_household\", col(\"total_rooms\") / col(\"households\"))\n",
        "\n",
        "# Calculate mean and standard deviation of 'rooms_per_household'\n",
        "mean_stddev = df_rooms_per_household.agg(\n",
        "    mean(\"rooms_per_household\").alias(\"mean_rooms_per_household\"),\n",
        "    stddev(\"rooms_per_household\").alias(\"stddev_rooms_per_household\")\n",
        ").collect()[0]\n",
        "\n",
        "mean_val = mean_stddev[\"mean_rooms_per_household\"]\n",
        "stddev_val = mean_stddev[\"stddev_rooms_per_household\"]\n",
        "\n",
        "# Identify outliers using z-score\n",
        "df_outliers = df_rooms_per_household.withColumn(\n",
        "    \"is_outlier_rooms_per_household\",\n",
        "    when(abs((col(\"rooms_per_household\") - mean_val) / stddev_val) > 3, True).otherwise(False)\n",
        ")\n",
        "\n",
        "# Show a few rows with the new columns\n",
        "df_outliers.select(\"total_rooms\", \"households\", \"rooms_per_household\", \"is_outlier_rooms_per_household\").show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+-------------------+------------------------------+\n",
            "|total_rooms|households|rooms_per_household|is_outlier_rooms_per_household|\n",
            "+-----------+----------+-------------------+------------------------------+\n",
            "|     5612.0|     472.0| 11.889830508474576|                         false|\n",
            "|     7650.0|     463.0|  16.52267818574514|                          true|\n",
            "|      720.0|     117.0|  6.153846153846154|                         false|\n",
            "|     1501.0|     226.0| 6.6415929203539825|                         false|\n",
            "|     1454.0|     262.0|  5.549618320610687|                         false|\n",
            "|     1387.0|     239.0|  5.803347280334728|                         false|\n",
            "|     2907.0|     633.0|  4.592417061611374|                         false|\n",
            "|      812.0|     158.0|  5.139240506329114|                         false|\n",
            "|     4789.0|    1056.0|  4.535037878787879|                         false|\n",
            "|     1497.0|     271.0|  5.523985239852398|                         false|\n",
            "+-----------+----------+-------------------+------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e3e0737"
      },
      "source": [
        "## Problem statement 5: compute average “bedrooms per room” for each region.\n",
        "\n",
        "### Subtask:\n",
        "Group by a suitable spatial identifier and calculate the average \"bedrooms per room\" ratio for each region.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "487743ea"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the \"bedrooms per room\" ratio and then group by the spatial identifier to calculate the average ratio for each group.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2165d0dd",
        "outputId": "433b4ea4-e43b-4650-b1f0-49dd12e94096"
      },
      "source": [
        "# Calculate 'bedrooms per room' ratio\n",
        "df_bedrooms_per_room = df_binned.withColumn(\"bedrooms_per_room\", col(\"total_bedrooms\") / col(\"total_rooms\"))\n",
        "\n",
        "# Group by spatial ID and calculate the average 'bedrooms per room' ratio\n",
        "avg_bedrooms_per_room_by_spatial_id = df_bedrooms_per_room.groupBy(\"spatial_id\") \\\n",
        "    .agg(avg(\"bedrooms_per_room\").alias(\"average_bedrooms_per_room\")) \\\n",
        "    .orderBy(\"spatial_id\") # Order by spatial ID\n",
        "\n",
        "# Show the results\n",
        "avg_bedrooms_per_room_by_spatial_id.show(10, truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------------------+\n",
            "|spatial_id |average_bedrooms_per_room|\n",
            "+-----------+-------------------------+\n",
            "|-114.4_34.1|0.22861724875267284      |\n",
            "|-114.5_34.4|0.24849673202614378      |\n",
            "|-114.6_33.5|0.22420907840440166      |\n",
            "|-114.6_33.6|0.22466839225517843      |\n",
            "|-114.6_34.8|0.20665468868772027      |\n",
            "|-114.7_32.7|0.42971590215527994      |\n",
            "|-114.7_33.4|0.2414486921529175       |\n",
            "|-114.7_33.6|0.19189511323003575      |\n",
            "|-114.7_33.9|0.24742268041237114      |\n",
            "|-114.7_34.8|0.20300088015517515      |\n",
            "+-----------+-------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce229ca2"
      },
      "source": [
        "## Problem statement 6: calculate population density (population per square unit) using latitude and longitude bins.\n",
        "\n",
        "### Subtask:\n",
        "Create latitude and longitude bins and calculate the population density within each bin.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59208d56"
      },
      "source": [
        "**Reasoning**:\n",
        "Create latitude and longitude bins, a spatial identifier, group by the spatial identifier, calculate the sum of population and count of data points within each group, and then calculate the population density and show the top 10 results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adab3cd1",
        "outputId": "8e95cb0f-9b80-41c9-b803-0df28d90c45e"
      },
      "source": [
        "from pyspark.sql.functions import floor, concat, lit\n",
        "\n",
        "# Create longitude bins of size 0.1\n",
        "df_binned = df.withColumn(\"longitude_bin\", floor(col(\"longitude\") * 10) / 10)\n",
        "\n",
        "# Create latitude bins of size 0.1\n",
        "df_binned = df_binned.withColumn(\"latitude_bin\", floor(col(\"latitude\") * 10) / 10)\n",
        "\n",
        "# Create a unique spatial identifier\n",
        "df_binned = df_binned.withColumn(\"spatial_id\", concat(col(\"longitude_bin\"), lit(\"_\"), col(\"latitude_bin\")))\n",
        "\n",
        "# Group by spatial ID and calculate sum of population and count of data points\n",
        "population_density_by_spatial_id = df_binned.groupBy(\"spatial_id\") \\\n",
        "    .agg(\n",
        "        F.sum(\"population\").alias(\"total_population\"),\n",
        "        F.count(\"*\").alias(\"data_point_count\")\n",
        "    )\n",
        "\n",
        "# Calculate population density (population per data point approximation)\n",
        "population_density_by_spatial_id = population_density_by_spatial_id.withColumn(\n",
        "    \"population_density\",\n",
        "    col(\"total_population\") / col(\"data_point_count\")\n",
        ")\n",
        "\n",
        "# Order by spatial_id\n",
        "population_density_by_spatial_id = population_density_by_spatial_id.orderBy(\"spatial_id\")\n",
        "\n",
        "# Show the first 10 rows\n",
        "population_density_by_spatial_id.select(\"spatial_id\", \"population_density\").show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+\n",
            "| spatial_id|population_density|\n",
            "+-----------+------------------+\n",
            "|-114.4_34.1|            1015.0|\n",
            "|-114.5_34.4|            1129.0|\n",
            "|-114.6_33.5|             624.0|\n",
            "|-114.6_33.6|1444.2857142857142|\n",
            "|-114.6_34.8|             581.0|\n",
            "|-114.7_32.7|             596.0|\n",
            "|-114.7_33.4|            1135.0|\n",
            "|-114.7_33.6|             666.0|\n",
            "|-114.7_33.9|              29.0|\n",
            "|-114.7_34.8|             977.0|\n",
            "+-----------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9797a1c4"
      },
      "source": [
        "## Problem statement 7: measure year-to-year percentage growth in median house value per region.\n",
        "\n",
        "### Subtask:\n",
        "If a time component is available in the data, group by region and year to calculate the year-to-year growth in median house value. (Note: The current dataset doesn't have a year column, so this step might need adaptation or skipping based on data availability).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c46ddbda"
      },
      "source": [
        "**Reasoning**:\n",
        "Check if a time component is available in the dataset and print a message if not.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b66be422",
        "outputId": "7f36d9f3-ed40-479c-e5b7-a60e57e0c5fd"
      },
      "source": [
        "# Problem Statement 7: Measure year-to-year percentage growth in median house value per region.\n",
        "# Check if a year column exists in the DataFrame\n",
        "if \"year\" not in df.columns:\n",
        "    print(\"The dataset does not contain a year column. Cannot perform year-to-year growth analysis.\")\n",
        "else:\n",
        "    # Assuming a 'year' column exists, proceed with the analysis\n",
        "    # (This part of the code will not be executed with the current dataset)\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset does not contain a year column. Cannot perform year-to-year growth analysis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbcbbac2"
      },
      "source": [
        "### Problem Statement 8: Split house values into deciles and compute average features per decile.\n",
        "\n",
        "### Subtask:\n",
        "Split house values into deciles and compute average features per decile.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61d6f6a2"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the decile boundaries for the `median_house_value` column, create a new column assigning each row to a decile, group by this decile column, compute the average of relevant numerical features, and display the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef941df8",
        "outputId": "6299369d-dc6a-4259-d8dc-b8a1e77f7744"
      },
      "source": [
        "from pyspark.sql.functions import ntile, avg\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# 1. Calculate the decile boundaries and assign deciles\n",
        "num_deciles = 10\n",
        "window_spec = Window.orderBy(\"median_house_value\")\n",
        "df_with_deciles = df.withColumn(\"house_value_decile\", ntile(num_deciles).over(window_spec))\n",
        "\n",
        "# 2. Compute the average of relevant numerical features per decile\n",
        "features_to_average = [\"median_income\", \"total_rooms\", \"population\", \"households\", \"housing_median_age\"]\n",
        "avg_features_per_decile = df_with_deciles.groupBy(\"house_value_decile\") \\\n",
        "    .agg(*(avg(col(feature)).alias(f\"avg_{feature}\") for feature in features_to_average)) \\\n",
        "    .orderBy(\"house_value_decile\")\n",
        "\n",
        "# 3. Display the resulting DataFrame\n",
        "avg_features_per_decile.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------------+------------------+------------------+------------------+----------------------+\n",
            "|house_value_decile| avg_median_income|   avg_total_rooms|    avg_population|    avg_households|avg_housing_median_age|\n",
            "+------------------+------------------+------------------+------------------+------------------+----------------------+\n",
            "|                 1| 2.113161647058823|1940.3211764705882|1191.3976470588236| 390.6935294117647|    29.129411764705882|\n",
            "|                 2| 2.564538117647061|2204.9964705882353| 1290.644705882353|436.91764705882355|     28.00176470588235|\n",
            "|                 3| 2.971263647058822| 2593.589411764706|1512.4205882352942|504.96235294117645|    26.716470588235293|\n",
            "|                 4|3.2229866470588164| 2578.684705882353|1595.9470588235295| 509.9758823529412|     26.86529411764706|\n",
            "|                 5| 3.539051647058819| 2514.946470588235|1567.6676470588236|505.34294117647056|    27.711764705882352|\n",
            "|                 6| 3.799730647058825|2659.7905882352943|1511.4711764705883| 522.9776470588235|    28.044117647058822|\n",
            "|                 7|  4.13893411764705|2827.4523529411763| 1516.414117647059| 545.7111764705883|     28.74529411764706|\n",
            "|                 8| 4.576101588235286|3061.6494117647057|1521.2494117647059| 566.7023529411765|    28.184117647058823|\n",
            "|                 9| 5.121977529411766| 3096.105882352941|1405.0464705882353| 543.0958823529412|    29.726470588235294|\n",
            "|                10| 6.788035411764709|2959.1076470588237|1183.4805882352941|            485.84|     32.76882352941176|\n",
            "+------------------+------------------+------------------+------------------+------------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "260379b1"
      },
      "source": [
        "## Problem Statement 8: Compare younger versus older houses in terms of price per room.\n",
        "\n",
        "### Subtask:\n",
        "Categorize houses into \"younger\" and \"older\" based on a housing age threshold and compare their average price per room.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74dd4cf7"
      },
      "source": [
        "**Reasoning**:\n",
        "Define an age threshold, categorize houses into younger/older, calculate price per room, group by category, calculate average price per room, and display the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f72fdad8",
        "outputId": "d24df5f7-7f9a-4389-9f25-267ae847ea53"
      },
      "source": [
        "# 1. Define a threshold for housing age\n",
        "age_threshold = 30\n",
        "\n",
        "# 2. Create a new column to label houses as \"younger\" or \"older\"\n",
        "df_aged = df.withColumn(\"housing_age_category\",\n",
        "                        when(col(\"housing_median_age\") < age_threshold, \"Younger\")\n",
        "                        .otherwise(\"Older\"))\n",
        "\n",
        "# 3. Calculate the \"price per room\" for each house\n",
        "df_aged = df_aged.withColumn(\"price_per_room\", col(\"median_house_value\") / col(\"total_rooms\"))\n",
        "\n",
        "# 4. Group the data by the \"younger\" or \"older\" categories\n",
        "# 5. Calculate the average \"price per room\" for each category\n",
        "avg_price_per_room_by_age = df_aged.groupBy(\"housing_age_category\") \\\n",
        "    .agg(avg(\"price_per_room\").alias(\"average_price_per_room\")) \\\n",
        "    .orderBy(\"housing_age_category\")\n",
        "\n",
        "# 6. Display the average price per room for younger and older houses\n",
        "avg_price_per_room_by_age.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------------------+\n",
            "|housing_age_category|average_price_per_room|\n",
            "+--------------------+----------------------+\n",
            "|               Older|    175.21477416972104|\n",
            "|             Younger|    132.36974394307552|\n",
            "+--------------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "019dc8a4"
      },
      "source": [
        "## Problem Statement 9: Perform regression residual analysis to find overvalued and undervalued areas.\n",
        "\n",
        "### Subtask:\n",
        "Build a regression model to predict house values and analyze the residuals to identify overvalued and undervalued areas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c75d79a0"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code cell failed because of an incorrect column name. This step will implement the regression model by selecting features, creating a feature vector, splitting the data, training a linear regression model, making predictions, calculating residuals, and displaying the areas with the largest positive and negative residuals.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee03012b",
        "outputId": "ec6165a5-fb4e-4acb-e7da-7691507d4c7c"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# 1. Select relevant features\n",
        "feature_columns = [\"median_income\", \"total_rooms\", \"housing_median_age\", \"population\", \"households\"]\n",
        "\n",
        "# Ensure all feature columns exist in the DataFrame and are numeric\n",
        "# Assuming the columns are already numeric based on previous steps and schema inference\n",
        "\n",
        "# 2. Prepare the data for the regression model by creating a feature vector\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data_with_features = assembler.transform(df)\n",
        "\n",
        "# 3. Split the data into training and testing sets (80/20 ratio)\n",
        "train_data, test_data = data_with_features.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# 4. Initialize and train a Linear Regression model on the training data\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"median_house_value\")\n",
        "lr_model = lr.fit(train_data)\n",
        "\n",
        "# 5. Make predictions on the testing data\n",
        "predictions = lr_model.transform(test_data)\n",
        "\n",
        "# 6. Calculate the residuals (actual house value - predicted house value)\n",
        "predictions_with_residuals = predictions.withColumn(\n",
        "    \"residual\", col(\"median_house_value\") - col(\"prediction\")\n",
        ")\n",
        "\n",
        "# 7. Analyze the residuals to identify potentially overvalued and undervalued areas\n",
        "# Show rows with the largest positive residuals (overvalued)\n",
        "print(\"Top 10 potentially overvalued areas (largest positive residuals):\")\n",
        "predictions_with_residuals.orderBy(col(\"residual\").desc()).select(\n",
        "    \"longitude\", \"latitude\", \"median_house_value\", \"prediction\", \"residual\"\n",
        ").show(10)\n",
        "\n",
        "# Show rows with the largest negative residuals (undervalued)\n",
        "print(\"Top 10 potentially undervalued areas (largest negative residuals):\")\n",
        "predictions_with_residuals.orderBy(col(\"residual\").asc()).select(\n",
        "    \"longitude\", \"latitude\", \"median_house_value\", \"prediction\", \"residual\"\n",
        ").show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 potentially overvalued areas (largest positive residuals):\n",
            "+---------+--------+------------------+------------------+------------------+\n",
            "|longitude|latitude|median_house_value|        prediction|          residual|\n",
            "+---------+--------+------------------+------------------+------------------+\n",
            "|  -121.89|    36.6|          500000.0|  72528.3438025353| 427471.6561974647|\n",
            "|  -117.22|   33.87|          500001.0|112411.74573294068| 387589.2542670593|\n",
            "|  -118.49|   34.01|          500001.0|118630.34626343299|  381370.653736567|\n",
            "|  -122.24|   37.49|          500001.0|125149.82793750707|374851.17206249293|\n",
            "|  -117.36|   33.17|          500001.0|130265.34362365448|369735.65637634555|\n",
            "|  -117.81|   33.69|          450000.0| 92101.43139906848|357898.56860093155|\n",
            "|  -117.08|   34.08|          500001.0|165689.94921083873|334311.05078916124|\n",
            "|  -117.55|   33.83|          500001.0| 165926.0075511645| 334074.9924488355|\n",
            "|  -117.27|   32.85|          488900.0|157308.51395660714|331591.48604339286|\n",
            "|  -122.17|   37.43|          387500.0|65286.347434669275|322213.65256533073|\n",
            "+---------+--------+------------------+------------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Top 10 potentially undervalued areas (largest negative residuals):\n",
            "+---------+--------+------------------+------------------+-------------------+\n",
            "|longitude|latitude|median_house_value|        prediction|           residual|\n",
            "+---------+--------+------------------+------------------+-------------------+\n",
            "|  -119.11|   35.42|          200000.0|519174.10762733116|-319174.10762733116|\n",
            "|  -118.52|   34.17|          259600.0| 511048.3403301963| -251448.3403301963|\n",
            "|  -122.44|   37.79|          500001.0| 748587.6971592241|-248586.69715922407|\n",
            "|  -118.34|   34.08|          500001.0| 739999.3104953406|-239998.31049534061|\n",
            "|  -118.41|   34.07|          500001.0| 730789.9900097814|-230788.99000978144|\n",
            "|  -118.12|   34.12|          500001.0| 730548.9051156653| -230547.9051156653|\n",
            "|  -118.49|   34.06|          500001.0| 724438.3178424062|-224437.31784240622|\n",
            "|  -122.05|   38.25|          105400.0|321668.19089431973|-216268.19089431973|\n",
            "|  -122.46|   37.79|          500001.0| 715575.2175857216|-215574.21758572164|\n",
            "|  -118.44|   34.09|          500001.0|  713513.936606606|  -213512.936606606|\n",
            "+---------+--------+------------------+------------------+-------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8766aeb3"
      },
      "source": [
        "## Problem Statement 11: Analyze temporal trends of income and house values over years.\n",
        "\n",
        "### Subtask:\n",
        "If a time component is available, analyze trends of income and house values over time. (Note: The current dataset doesn't have a year column, so this step might need adaptation or skipping based on data availability).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c12fdc1"
      },
      "source": [
        "**Reasoning**:\n",
        "Check if the 'year' column exists in the DataFrame and print a message if it doesn't exist, as the analysis requires this column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85c57d67",
        "outputId": "6a0e083d-4116-4d9f-ea04-36c20e58aebf"
      },
      "source": [
        "# Check if a year column exists in the DataFrame\n",
        "if \"year\" not in df.columns:\n",
        "    print(\"The dataset does not contain a year column. Cannot perform analysis of temporal trends.\")\n",
        "else:\n",
        "    # Assuming a 'year' column exists, proceed with the analysis\n",
        "    # Group by year and calculate average income and house value\n",
        "    temporal_trends = df.groupBy(\"year\") \\\n",
        "        .agg(\n",
        "            avg(\"median_income\").alias(\"average_median_income\"),\n",
        "            avg(\"median_house_value\").alias(\"average_median_house_value\")\n",
        "        ) \\\n",
        "        .orderBy(\"year\")\n",
        "\n",
        "    # Show the results\n",
        "    temporal_trends.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset does not contain a year column. Cannot perform analysis of temporal trends.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ef307d7"
      },
      "source": [
        "## Problem Statement 12: Compute the “affordability index” (income-to-house-value ratio) per region.\n",
        "\n",
        "### Subtask:\n",
        "Compute the “affordability index” (income-to-house-value ratio) per region.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "168fe236"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires calculating the affordability index by grouping the pre-binned data by spatial ID and computing the ratio of average median income to average median house value. This can be done in a single step using groupBy and agg functions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f42d55fe",
        "outputId": "3209c85c-88f8-443c-92e3-ddca3d28df65"
      },
      "source": [
        "# Group by spatial ID and calculate average median income and average median house value\n",
        "affordability_index_by_spatial_id = df_binned.groupBy(\"spatial_id\") \\\n",
        "    .agg(\n",
        "        avg(\"median_income\").alias(\"average_median_income\"),\n",
        "        avg(\"median_house_value\").alias(\"average_median_house_value\")\n",
        "    )\n",
        "\n",
        "# Compute the affordability index (average median income / average median house value)\n",
        "affordability_index_by_spatial_id = affordability_index_by_spatial_id.withColumn(\n",
        "    \"affordability_index\",\n",
        "    col(\"average_median_income\") / col(\"average_median_house_value\")\n",
        ")\n",
        "\n",
        "# Display the results\n",
        "affordability_index_by_spatial_id.select(\"spatial_id\", \"affordability_index\").show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+\n",
            "| spatial_id| affordability_index|\n",
            "+-----------+--------------------+\n",
            "|-116.2_33.7|3.793564356435644E-5|\n",
            "|-117.4_33.7|1.985877513711151...|\n",
            "|-118.0_33.8|2.005194915954404...|\n",
            "|-119.7_36.2|2.545164718384697E-5|\n",
            "|-120.0_37.0|3.531073446327684E-5|\n",
            "|-122.0_37.1|2.223174374861695...|\n",
            "|-122.5_38.4|1.361795309830719E-5|\n",
            "|-117.1_36.4|1.400093339555970...|\n",
            "|-118.9_34.2|2.034056441963639...|\n",
            "|-118.9_34.0|1.623236753526492...|\n",
            "+-----------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8340c3e4"
      },
      "source": [
        "## Problem Statement 13: Run k-means clustering on features and profile each cluster.\n",
        "\n",
        "### Subtask:\n",
        "Run K-Means clustering on features and profile each cluster.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8be4b32a"
      },
      "source": [
        "**Reasoning**:\n",
        "Select relevant features, create a feature vector, initialize and train a K-Means model, add cluster predictions, group by cluster, calculate average features per cluster, and display the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75cdc26e",
        "outputId": "497a9877-77ad-4d49-8563-6d0e7f50ca8f"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.sql.functions import avg\n",
        "\n",
        "# 1. Select relevant numerical features for clustering\n",
        "feature_columns = [\"median_income\", \"total_rooms\", \"housing_median_age\", \"population\", \"households\", \"median_house_value\"]\n",
        "\n",
        "# 2. Create a feature vector using VectorAssembler\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data_with_features = assembler.transform(df)\n",
        "\n",
        "# 3. Initialize and train a K-Means model with a reasonable number of clusters (e.g., 5)\n",
        "k = 5\n",
        "kmeans = KMeans().setK(k).setSeed(1)\n",
        "model = kmeans.fit(data_with_features)\n",
        "\n",
        "# 4. Add the cluster predictions to the original DataFrame\n",
        "predictions = model.transform(data_with_features)\n",
        "\n",
        "# 5. Group the DataFrame by the cluster labels and calculate the average of the original features for each cluster to profile them.\n",
        "cluster_profiling = predictions.groupBy(\"prediction\") \\\n",
        "    .agg(*(avg(col(feature)).alias(f\"avg_{feature}\") for feature in feature_columns)) \\\n",
        "    .orderBy(\"prediction\")\n",
        "\n",
        "# 6. Display the average feature values for each cluster.\n",
        "print(\"Cluster Profiling (Average Feature Values per Cluster):\")\n",
        "cluster_profiling.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Profiling (Average Feature Values per Cluster):\n",
            "+----------+-----------------+------------------+----------------------+------------------+-----------------+----------------------+\n",
            "|prediction|avg_median_income|   avg_total_rooms|avg_housing_median_age|    avg_population|   avg_households|avg_median_house_value|\n",
            "+----------+-----------------+------------------+----------------------+------------------+-----------------+----------------------+\n",
            "|         0|3.488406385792561| 2605.440015114302|     27.35424145097298|1566.8649159266956|515.2350273946722|     164932.6279992443|\n",
            "|         1|7.057088897168406|2925.5141579731744|    33.216095380029806|1147.4873323397915|474.6475409836066|    481192.48435171385|\n",
            "|         2|2.498809942881325| 2195.939496509414|     28.14385445314153| 1306.334461603554|435.5548973979268|     89966.02411677597|\n",
            "|         3|4.353013843253436| 2939.051440883383|    28.421761378938864|1515.5375706975492|554.7686506867761|    245296.20253164557|\n",
            "|         4|5.252708779220783|3081.9516883116885|    30.177142857142858|1385.5475324675324| 539.185974025974|    347694.85714285716|\n",
            "+----------+-----------------+------------------+----------------------+------------------+-----------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4074d90c"
      },
      "source": [
        "## Problem Statement 14: Find nearest neighboring blocks and compare their house value differences.\n",
        "\n",
        "### Subtask:\n",
        "Find nearest neighboring blocks and compare their house value differences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50cc511b"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step is to select the necessary columns from the PySpark DataFrame and convert it to a Pandas DataFrame for easier spatial calculations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f99a42d"
      },
      "source": [
        "# 1. Select the longitude, latitude, and median house value columns\n",
        "selected_cols_df = df.select(\"longitude\", \"latitude\", \"median_house_value\")\n",
        "\n",
        "# 2. Convert the selected PySpark DataFrame to a Pandas DataFrame\n",
        "selected_cols_pandas_df = selected_cols_df.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00e7dadb"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the pairwise distances between points and find the nearest neighbor for each point in the Pandas DataFrame, then compute the house value difference.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "E6NaG4B_ozRq",
        "outputId": "36fcae2e-78de-4298-8a0c-4f5c02ef0510"
      },
      "source": [
        "from scipy.spatial.distance import cdist\n",
        "import numpy as np\n",
        "\n",
        "# 3. Calculate the pairwise distances between all data points\n",
        "coords = selected_cols_pandas_df[['longitude', 'latitude']].values\n",
        "distance_matrix = cdist(coords, coords)\n",
        "\n",
        "# 4. For each data point, find its nearest neighbor (excluding itself)\n",
        "# Initialize lists to store nearest neighbor index and distance\n",
        "nearest_neighbor_indices = []\n",
        "house_value_differences = []\n",
        "\n",
        "for i in range(len(distance_matrix)):\n",
        "    # Sort distances for the current point and get indices\n",
        "    sorted_indices = np.argsort(distance_matrix[i])\n",
        "    # The nearest neighbor (excluding self) is the second element\n",
        "    nearest_neighbor_index = sorted_indices[1]\n",
        "    nearest_neighbor_indices.append(nearest_neighbor_index)\n",
        "\n",
        "    # 5. Calculate the absolute difference in median house value using numpy.abs\n",
        "    diff = np.abs(selected_cols_pandas_df.iloc[i]['median_house_value'] - selected_cols_pandas_df.iloc[nearest_neighbor_index]['median_house_value'])\n",
        "    house_value_differences.append(diff)\n",
        "\n",
        "# Add the differences to the pandas DataFrame\n",
        "selected_cols_pandas_df['nearest_neighbor_house_value_difference'] = house_value_differences\n",
        "\n",
        "# 6. Display the average house value difference or examples\n",
        "print(\"Average house value difference between nearest neighbors:\", np.mean(house_value_differences))\n",
        "\n",
        "# Display examples of data points and their nearest neighbors with differences\n",
        "print(\"\\nExamples of nearest neighbors and house value differences:\")\n",
        "display(selected_cols_pandas_df[['longitude', 'latitude', 'median_house_value', 'nearest_neighbor_house_value_difference']].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average house value difference between nearest neighbors: 31516.249\n",
            "\n",
            "Examples of nearest neighbors and house value differences:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   longitude  latitude  median_house_value  \\\n",
              "0    -114.31     34.19             66900.0   \n",
              "1    -114.47     34.40             80100.0   \n",
              "2    -114.56     33.69             85700.0   \n",
              "3    -114.57     33.64             73400.0   \n",
              "4    -114.57     33.57             65500.0   \n",
              "\n",
              "   nearest_neighbor_house_value_difference  \n",
              "0                                  13200.0  \n",
              "1                                  13200.0  \n",
              "2                                  12300.0  \n",
              "3                                    600.0  \n",
              "4                                  16900.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44d800f8-e546-4ebd-b70d-e4e1ff81db30\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>median_house_value</th>\n",
              "      <th>nearest_neighbor_house_value_difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>66900.0</td>\n",
              "      <td>13200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>80100.0</td>\n",
              "      <td>13200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>85700.0</td>\n",
              "      <td>12300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>73400.0</td>\n",
              "      <td>600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>65500.0</td>\n",
              "      <td>16900.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44d800f8-e546-4ebd-b70d-e4e1ff81db30')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-44d800f8-e546-4ebd-b70d-e4e1ff81db30 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-44d800f8-e546-4ebd-b70d-e4e1ff81db30');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-31340cf0-c2bd-43af-b193-40e28d714595\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31340cf0-c2bd-43af-b193-40e28d714595')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-31340cf0-c2bd-43af-b193-40e28d714595 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(selected_cols_pandas_df[['longitude', 'latitude', 'median_house_value', 'nearest_neighbor_house_value_difference']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11216059914247682,\n        \"min\": -114.57,\n        \"max\": -114.31,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -114.47,\n          -114.57,\n          -114.31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3723842101915701,\n        \"min\": 33.57,\n        \"max\": 34.4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          34.4,\n          33.57,\n          33.69\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_house_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8611.15555544086,\n        \"min\": 65500.0,\n        \"max\": 85700.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          80100.0,\n          65500.0,\n          85700.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nearest_neighbor_house_value_difference\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6205.884304432367,\n        \"min\": 600.0,\n        \"max\": 16900.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          12300.0,\n          16900.0,\n          13200.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0370d50"
      },
      "source": [
        "## Problem Statement 15: Compute moving average of house values along longitude (spatial trend).\n",
        "\n",
        "### Subtask:\n",
        "Order data by longitude and compute a moving average of house values to identify spatial trends.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5efd6aa4"
      },
      "source": [
        "**Reasoning**:\n",
        "Order the data by longitude and compute the moving average of median house value using a window function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "998affb2",
        "outputId": "e47d307e-38f6-4a38-8ddd-7b952dadfa65"
      },
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import col, avg\n",
        "\n",
        "# 1. Order the DataFrame by longitude\n",
        "df_ordered_by_longitude = df.orderBy(\"longitude\")\n",
        "\n",
        "# 2. Define a window specification for the moving average\n",
        "window_spec = Window.orderBy(\"longitude\").rowsBetween(-100, 0) # Include 100 preceding rows and the current row\n",
        "\n",
        "# 3. Compute the moving average of the median_house_value\n",
        "df_with_moving_average = df_ordered_by_longitude.withColumn(\n",
        "    \"moving_avg_median_house_value\",\n",
        "    avg(\"median_house_value\").over(window_spec)\n",
        ")\n",
        "\n",
        "# 4. Display a few rows showing longitude, median_house_value, and the moving average\n",
        "df_with_moving_average.select(\"longitude\", \"median_house_value\", \"moving_avg_median_house_value\").show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------+-----------------------------+\n",
            "|longitude|median_house_value|moving_avg_median_house_value|\n",
            "+---------+------------------+-----------------------------+\n",
            "|  -124.35|           94600.0|                      94600.0|\n",
            "|   -124.3|          103600.0|                      99100.0|\n",
            "|   -124.3|           85800.0|            94666.66666666667|\n",
            "|  -124.27|           79000.0|                      90750.0|\n",
            "|  -124.26|          111400.0|                      94880.0|\n",
            "|  -124.25|           76100.0|                      91750.0|\n",
            "|  -124.23|           73200.0|                      89100.0|\n",
            "|  -124.23|           50800.0|                      84312.5|\n",
            "|  -124.23|          106700.0|                      86800.0|\n",
            "|  -124.22|           78300.0|                      85950.0|\n",
            "+---------+------------------+-----------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b56c88cb"
      },
      "source": [
        "## Problem Statement 16: Compare house prices across low, medium, and high population density buckets.\n",
        "\n",
        "### Subtask:\n",
        "Compare house prices across low, medium, and high population density buckets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f61a8c67"
      },
      "source": [
        "**Reasoning**:\n",
        "Define population density buckets, assign each spatial ID to a bucket, join with the binned dataframe, group by bucket, calculate the average median house value, and display the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d61c10fa",
        "outputId": "68b2ac2e-28a0-461c-e7cd-09c9d78cfb1b"
      },
      "source": [
        "from pyspark.sql.functions import when, col, avg\n",
        "\n",
        "# 1. Define population density bucket boundaries and labels\n",
        "# Using quantiles of the population_density to define boundaries\n",
        "quantiles = population_density_by_spatial_id.approxQuantile(\"population_density\", [0.33, 0.66], 0.01)\n",
        "low_threshold = quantiles[0]\n",
        "medium_threshold = quantiles[1]\n",
        "\n",
        "# Define buckets: Low (< low_threshold), Medium (low_threshold to medium_threshold), High (> medium_threshold)\n",
        "population_density_by_spatial_id = population_density_by_spatial_id.withColumn(\n",
        "    \"population_density_bucket\",\n",
        "    when(col(\"population_density\") < low_threshold, \"Low\")\n",
        "    .when((col(\"population_density\") >= low_threshold) & (col(\"population_density\") < medium_threshold), \"Medium\")\n",
        "    .otherwise(\"High\")\n",
        ")\n",
        "\n",
        "# 2. Join with the binned DataFrame to get median_house_value per spatial_id and bucket\n",
        "df_joined = df_binned.join(\n",
        "    population_density_by_spatial_id.select(\"spatial_id\", \"population_density_bucket\"),\n",
        "    on=\"spatial_id\",\n",
        "    how=\"inner\"\n",
        ")\n",
        "\n",
        "# 3. Group by population density bucket and calculate the average median_house_value\n",
        "average_house_value_by_density_bucket = df_joined.groupBy(\"population_density_bucket\") \\\n",
        "    .agg(avg(\"median_house_value\").alias(\"average_median_house_value\")) \\\n",
        "    .orderBy(\"population_density_bucket\")\n",
        "\n",
        "# 4. Display the results\n",
        "average_house_value_by_density_bucket.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------+--------------------------+\n",
            "|population_density_bucket|average_median_house_value|\n",
            "+-------------------------+--------------------------+\n",
            "|                     High|        195140.45490822027|\n",
            "|                      Low|        144757.57352941178|\n",
            "|                   Medium|        230140.08107736704|\n",
            "+-------------------------+--------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2499d7b"
      },
      "source": [
        "## Problem Statement 17: Compare elasticities of house value with income and total bedrooms using correlations.\n",
        "\n",
        "### Subtask:\n",
        "Compare elasticities of house value with income and total bedrooms using correlations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be54908e"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the Pearson correlation coefficient between `median_house_value` and `median_income`, and between `median_house_value` and `total_bedrooms`. Then print the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI6KIKOepL97",
        "outputId": "17f2ca05-e0d5-41ce-aa46-69f1e59c16ce"
      },
      "source": [
        "# Calculate the Pearson correlation coefficient between median_house_value and median_income\n",
        "correlation_income_house_value = df.select(corr(\"median_house_value\", \"median_income\")).collect()[0][0]\n",
        "\n",
        "# Calculate the Pearson correlation coefficient between median_house_value and total_bedrooms\n",
        "correlation_bedrooms_house_value = df.select(corr(\"median_house_value\", \"total_bedrooms\")).collect()[0][0]\n",
        "\n",
        "# Print the calculated correlation coefficients\n",
        "print(f\"Pearson correlation between Median House Value and Median Income: {correlation_income_house_value}\")\n",
        "print(f\"Pearson correlation between Median House Value and Total Bedrooms: {correlation_bedrooms_house_value}\")\n",
        "\n",
        "# Use Python's built-in abs() for comparing float values\n",
        "if __builtins__.abs(correlation_income_house_value) > __builtins__.abs(correlation_bedrooms_house_value):\n",
        "    print(\"\\nMedian Income has a stronger correlation with Median House Value than Total Bedrooms.\")\n",
        "elif __builtins__.abs(correlation_income_house_value) < __builtins__.abs(correlation_bedrooms_house_value):\n",
        "    print(\"\\nTotal Bedrooms has a stronger correlation with Median House Value than Median Income.\")\n",
        "else:\n",
        "    print(\"\\nMedian Income and Total Bedrooms have similar correlation strengths with Median House Value.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson correlation between Median House Value and Median Income: 0.6918706037806676\n",
            "Pearson correlation between Median House Value and Total Bedrooms: 0.04578305197954698\n",
            "\n",
            "Median Income has a stronger correlation with Median House Value than Total Bedrooms.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d25ba56f"
      },
      "source": [
        "## Problem Statement 18: Create a histogram or bucket count of housing median age.\n",
        "\n",
        "### Subtask:\n",
        "Create a histogram or bucket count of housing median age.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4399982"
      },
      "source": [
        "**Reasoning**:\n",
        "Define appropriate bins for housing median age, create a new column for age buckets, group by these buckets, count the entries in each bucket, and display the results to create a histogram or bucket count of housing median age.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "331ae2d4",
        "outputId": "166cbe0d-f271-43de-f952-e416076e7ab4"
      },
      "source": [
        "from pyspark.sql.functions import col, count, when\n",
        "\n",
        "# 1. Define appropriate bins or buckets for the 'housing_median_age' column.\n",
        "age_bins = [0, 10, 20, 30, 40, 50, float('inf')]\n",
        "age_labels = [\"0-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50+\"]\n",
        "\n",
        "# 2. Create a new column in the DataFrame that assigns each data point to its corresponding age bucket.\n",
        "df_age_histogram = df.withColumn(\"age_bucket\",\n",
        "    when((col(\"housing_median_age\") >= age_bins[0]) & (col(\"housing_median_age\") < age_bins[1]), age_labels[0])\n",
        "    .when((col(\"housing_median_age\") >= age_bins[1]) & (col(\"housing_median_age\") < age_bins[2]), age_labels[1])\n",
        "    .when((col(\"housing_median_age\") >= age_bins[2]) & (col(\"housing_median_age\") < age_bins[3]), age_labels[2])\n",
        "    .when((col(\"housing_median_age\") >= age_bins[3]) & (col(\"housing_median_age\") < age_bins[4]), age_labels[3])\n",
        "    .when((col(\"housing_median_age\") >= age_bins[4]) & (col(\"housing_median_age\") < age_bins[5]), age_labels[4])\n",
        "    .otherwise(age_labels[5])\n",
        ")\n",
        "\n",
        "# 3. Group the DataFrame by the newly created age bucket column.\n",
        "# 4. Count the number of data points in each age bucket.\n",
        "age_bucket_counts = df_age_histogram.groupBy(\"age_bucket\").agg(count(\"*\").alias(\"count\"))\n",
        "\n",
        "# Order by age bucket label for better readability\n",
        "age_bucket_counts = age_bucket_counts.orderBy(\"age_bucket\")\n",
        "\n",
        "# 5. Display the age buckets and their corresponding counts.\n",
        "age_bucket_counts.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|age_bucket|count|\n",
            "+----------+-----+\n",
            "|       0-9| 1087|\n",
            "|     10-19| 3739|\n",
            "|     20-29| 3985|\n",
            "|     30-39| 4770|\n",
            "|     40-49| 2223|\n",
            "|       50+| 1196|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78b67e4d"
      },
      "source": [
        "## Problem Statement 19: For each income decile, compute variance in house values to study price dispersion.\n",
        "\n",
        "### Subtask:\n",
        "For each income decile, compute variance in house values to study price dispersion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15f418e7"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement steps 1-5 from the instructions to compute the variance of house values for each income decile.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c25583e2"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the `var` function was not imported correctly. I need to import `variance` instead of `var` from `pyspark.sql.functions` to calculate the variance. I will also include all the steps in the same code block.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9t1WfZipXDk",
        "outputId": "e9759924-dcbd-4785-ccda-8915137cf702"
      },
      "source": [
        "from pyspark.sql.functions import ntile, variance\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# 1. Define the number of income deciles\n",
        "num_deciles = 10\n",
        "\n",
        "# 2. Calculate the income decile for each row\n",
        "window_spec = Window.orderBy(\"median_income\")\n",
        "df_with_income_deciles = df.withColumn(\"income_decile\", ntile(num_deciles).over(window_spec))\n",
        "\n",
        "# 3. Group by the income decile column\n",
        "# 4. For each income decile group, compute the variance of the median_house_value\n",
        "variance_by_income_decile = df_with_income_deciles.groupBy(\"income_decile\") \\\n",
        "    .agg(variance(\"median_house_value\").alias(\"variance_house_value\")) \\\n",
        "    .orderBy(\"income_decile\")\n",
        "\n",
        "# 5. Display the income decile and its corresponding variance\n",
        "variance_by_income_decile.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------------+\n",
            "|income_decile|variance_house_value|\n",
            "+-------------+--------------------+\n",
            "|            1| 4.987309776331106E9|\n",
            "|            2| 4.825538064584687E9|\n",
            "|            3| 5.358506496132984E9|\n",
            "|            4| 6.206438835921972E9|\n",
            "|            5| 7.335664529671689E9|\n",
            "|            6| 8.083045389515898E9|\n",
            "|            7| 8.644757953040173E9|\n",
            "|            8| 8.037860359123954E9|\n",
            "|            9| 8.593498157851992E9|\n",
            "|           10| 9.554170888789082E9|\n",
            "+-------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1082e9be"
      },
      "source": [
        "## Problem Statement 20: Compare border versus interior blocks within each region to detect “edge effects.”\n",
        "\n",
        "### Subtask:\n",
        "Compare border versus interior blocks within each region to detect “edge effects.”\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "105bfa6b"
      },
      "source": [
        "**Reasoning**:\n",
        "To classify blocks as border or interior, I need to count the number of distinct spatial bins present in the dataset. This count will help determine if a block's neighbors are within the dataset's boundaries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cc35eda",
        "outputId": "abf6a082-2810-4ad7-83ac-bd3f22cb2761"
      },
      "source": [
        "# Calculate the number of distinct spatial bins\n",
        "distinct_spatial_bins_count = df_binned.select(\"spatial_id\").distinct().count()\n",
        "print(f\"Number of distinct spatial bins: {distinct_spatial_bins_count}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of distinct spatial bins: 1456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "328b94b3"
      },
      "source": [
        "**Reasoning**:\n",
        "To determine if a spatial bin is a border or interior, I need to know the set of all spatial bins present in the dataset and the set of neighboring spatial bins for each bin. I will collect the distinct spatial IDs to a list.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cda5ac6b"
      },
      "source": [
        "# Collect all distinct spatial IDs\n",
        "all_spatial_ids = [row['spatial_id'] for row in df_binned.select(\"spatial_id\").distinct().collect()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e15bf166"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that I have the list of all spatial IDs, I need to define a function that determines if a given spatial ID is a \"border\" or \"interior\" block by checking if any of its potential neighbors (based on adjacent longitude/latitude bins) are not present in the list of all spatial IDs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28d73bde"
      },
      "source": [
        "def is_border_block(spatial_id, all_spatial_ids):\n",
        "    \"\"\"\n",
        "    Checks if a spatial bin is a border block.\n",
        "\n",
        "    A spatial bin is considered a border block if any of its 8 potential\n",
        "    neighbors (including diagonals) are not present in the dataset.\n",
        "\n",
        "    Args:\n",
        "        spatial_id (str): The spatial ID in the format \"longitude_bin_latitude_bin\".\n",
        "        all_spatial_ids (list): A list of all distinct spatial IDs in the dataset.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the spatial bin is a border block, False otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        lon_bin, lat_bin = map(float, spatial_id.split('_'))\n",
        "    except ValueError:\n",
        "        # Handle potential invalid spatial_id format\n",
        "        return True # Treat invalid formats as border for safety\n",
        "\n",
        "    # Define potential neighbor offsets\n",
        "    lon_offsets = [-0.1, 0, 0.1]\n",
        "    lat_offsets = [-0.1, 0, 0.1]\n",
        "\n",
        "    for lon_offset in lon_offsets:\n",
        "        for lat_offset in lat_offsets:\n",
        "            # Skip the current block itself\n",
        "            if lon_offset == 0 and lat_offset == 0:\n",
        "                continue\n",
        "\n",
        "            neighbor_lon_bin = round(lon_bin + lon_offset, 1)\n",
        "            neighbor_lat_bin = round(lat_bin + lat_offset, 1)\n",
        "            neighbor_spatial_id = f\"{neighbor_lon_bin}_{neighbor_lat_bin}\"\n",
        "\n",
        "            # If a neighbor is not in the list of all spatial IDs, it's a border block\n",
        "            if neighbor_spatial_id not in all_spatial_ids:\n",
        "                return True\n",
        "\n",
        "    # If all potential neighbors are in the list, it's an interior block\n",
        "    return False\n",
        "\n",
        "# Convert the list of spatial IDs to a broadcast variable for efficient lookup\n",
        "all_spatial_ids_broadcast = spark.sparkContext.broadcast(all_spatial_ids)\n",
        "\n",
        "# Apply the function to the DataFrame to create the 'border_status' column\n",
        "# This requires converting to RDD and back, or using UDF, UDF is generally better.\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import BooleanType\n",
        "\n",
        "is_border_udf = udf(lambda x: is_border_block(x, all_spatial_ids_broadcast.value), BooleanType())\n",
        "\n",
        "df_with_border_status = df_binned.withColumn(\"is_border\", is_border_udf(col(\"spatial_id\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44bade41"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that I have classified each block as border or interior, I need to group the data by spatial region and the border status and calculate relevant statistics to compare border versus interior blocks within each region.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7b907e4",
        "outputId": "99d98420-514e-49a4-d0c1-51ba9a5b1a5e"
      },
      "source": [
        "# Group by spatial region and border status and calculate average statistics\n",
        "border_interior_comparison = df_with_border_status.groupBy(\"spatial_id\", \"is_border\") \\\n",
        "    .agg(\n",
        "        avg(\"median_house_value\").alias(\"average_median_house_value\"),\n",
        "        avg(\"median_income\").alias(\"average_median_income\"),\n",
        "        avg(\"total_rooms\").alias(\"average_total_rooms\"),\n",
        "        avg(\"population\").alias(\"average_population\")\n",
        "    ) \\\n",
        "    .orderBy(\"spatial_id\", \"is_border\")\n",
        "\n",
        "# Display the comparison of statistics\n",
        "print(\"Comparison of Border vs Interior Blocks per Spatial Region:\")\n",
        "border_interior_comparison.show(100, truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison of Border vs Interior Blocks per Spatial Region:\n",
            "+-----------+---------+--------------------------+---------------------+-------------------+------------------+\n",
            "|spatial_id |is_border|average_median_house_value|average_median_income|average_total_rooms|average_population|\n",
            "+-----------+---------+--------------------------+---------------------+-------------------+------------------+\n",
            "|-114.4_34.1|true     |66900.0                   |1.4936               |5612.0             |1015.0            |\n",
            "|-114.5_34.4|true     |80100.0                   |1.82                 |7650.0             |1129.0            |\n",
            "|-114.6_33.5|true     |65500.0                   |1.925                |1454.0             |624.0             |\n",
            "|-114.6_33.6|true     |74628.57142857143         |2.4780142857142855   |2433.285714285714  |1444.2857142857142|\n",
            "|-114.6_34.8|true     |48300.0                   |1.94955              |1154.5             |581.0             |\n",
            "|-114.7_32.7|true     |38000.0                   |0.9735               |960.0              |596.0             |\n",
            "|-114.7_33.4|true     |44400.0                   |1.6395               |1491.0             |1135.0            |\n",
            "|-114.7_33.6|true     |94900.0                   |2.9653               |1678.0             |666.0             |\n",
            "|-114.7_33.9|true     |27500.0                   |1.2656               |97.0               |29.0              |\n",
            "|-114.7_34.8|true     |62700.0                   |2.3560666666666665   |2108.3333333333335 |977.0             |\n",
            "|-114.8_33.4|true     |59200.0                   |0.8964               |796.0              |227.0             |\n",
            "|-115.0_33.8|true     |71300.0                   |3.2097               |644.0              |137.0             |\n",
            "|-115.0_34.5|true     |50000.0                   |1.625                |350.0              |119.0             |\n",
            "|-115.3_33.5|true     |53500.0                   |1.625                |1706.0             |3424.0            |\n",
            "|-115.4_32.7|true     |121050.0                  |3.9697999999999998   |859.5              |506.0             |\n",
            "|-115.4_32.8|true     |80250.0                   |2.5614375000000003   |1238.75            |823.375           |\n",
            "|-115.5_32.6|true     |78983.33333333333         |1.7512833333333333   |2501.5             |2089.0            |\n",
            "|-115.5_32.7|true     |142500.0                  |3.4107               |330.0              |822.0             |\n",
            "|-115.5_32.8|true     |95650.0                   |2.98775              |900.5              |631.0             |\n",
            "|-115.5_32.9|true     |107800.0                  |3.4038               |1141.0             |684.0             |\n",
            "|-115.5_33.1|true     |40000.0                   |1.0                  |1234.0             |777.0             |\n",
            "|-115.6_32.6|true     |78266.66666666667         |2.421466666666667    |2203.6666666666665 |2033.3333333333333|\n",
            "|-115.6_32.7|true     |81494.73684210527         |3.1098526315789474   |1627.3684210526317 |1110.0            |\n",
            "|-115.6_32.8|true     |73371.42857142857         |2.810057142857143    |1347.9285714285713 |893.0714285714286 |\n",
            "|-115.6_32.9|true     |76942.85714285714         |2.5952857142857146   |1928.4285714285713 |1265.5            |\n",
            "|-115.6_33.1|true     |53633.333333333336        |2.0477666666666665   |1153.3333333333333 |893.3333333333334 |\n",
            "|-115.6_33.2|true     |57900.0                   |2.05315              |1352.0             |729.5             |\n",
            "|-115.6_33.8|true     |71700.0                   |3.1827               |1161.0             |724.0             |\n",
            "|-115.6_34.2|true     |42500.0                   |1.3333               |540.0              |122.0             |\n",
            "|-115.6_34.9|true     |40000.0                   |2.5391               |807.0              |246.0             |\n",
            "|-115.7_32.7|true     |55200.0                   |2.1792               |1564.0             |1161.0            |\n",
            "|-115.7_32.8|true     |125000.0                  |3.1667               |1228.0             |569.0             |\n",
            "|-115.7_33.0|true     |61600.0                   |2.1715999999999998   |1065.0             |755.5             |\n",
            "|-115.8_32.7|true     |87500.0                   |2.0938               |348.0              |123.0             |\n",
            "|-115.8_32.8|true     |93800.0                   |2.2083               |472.0              |206.0             |\n",
            "|-115.8_33.0|true     |87500.0                   |2.9                  |452.0              |258.0             |\n",
            "|-115.8_33.2|true     |47500.0                   |5.3374               |96.0               |30.0              |\n",
            "|-115.8_33.3|true     |40000.0                   |1.49295              |1167.5             |407.0             |\n",
            "|-115.9_32.9|true     |32500.0                   |4.0208               |208.0              |51.0              |\n",
            "|-115.9_33.3|true     |62800.0                   |1.7857               |1210.0             |329.0             |\n",
            "|-115.9_33.4|true     |68900.0                   |2.0347               |1660.0             |637.0             |\n",
            "|-115.9_34.2|true     |41000.0                   |1.3571               |3868.0             |890.0             |\n",
            "|-116.0_32.7|true     |43900.0                   |1.4338               |1134.0             |329.0             |\n",
            "|-116.0_33.1|true     |51300.0                   |1.2639               |245.0              |81.0              |\n",
            "|-116.0_33.2|true     |53800.0                   |1.8958               |99.0               |37.0              |\n",
            "|-116.0_33.3|true     |58625.0                   |1.55395              |301.75             |94.0              |\n",
            "|-116.0_33.4|true     |54300.0                   |2.0109               |1945.0             |515.0             |\n",
            "|-116.0_35.5|true     |67500.0                   |3.4028               |1321.0             |754.0             |\n",
            "|-116.1_33.3|true     |81300.0                   |1.7292               |290.0              |135.0             |\n",
            "|-116.1_33.4|true     |62800.0                   |2.8684               |1996.0             |659.0             |\n",
            "|-116.1_33.5|true     |66400.0                   |1.7344               |2985.0             |4042.0            |\n",
            "|-116.1_33.8|true     |76100.0                   |2.425                |381.0              |182.0             |\n",
            "|-116.1_34.1|true     |73125.0                   |3.0712               |5172.75            |2283.75           |\n",
            "|-116.1_34.2|true     |66900.0                   |1.3371               |1202.0             |383.0             |\n",
            "|-116.2_32.6|true     |61800.0                   |1.4648               |1608.0             |567.0             |\n",
            "|-116.2_33.5|true     |79300.0                   |1.8913499999999999   |2067.0             |2474.5            |\n",
            "|-116.2_33.6|true     |82290.0                   |2.22601              |1462.3             |1573.6            |\n",
            "|-116.2_33.7|true     |60600.0                   |2.2989               |2399.0             |2654.0            |\n",
            "|-116.2_34.1|true     |82600.0                   |3.0139               |3312.0             |1251.0            |\n",
            "|-116.2_34.2|true     |47800.0                   |1.875                |3298.0             |763.0             |\n",
            "|-116.3_33.0|true     |83700.0                   |1.9875               |934.0              |452.0             |\n",
            "|-116.3_33.6|true     |162740.0                  |4.283040000000001    |2733.6             |834.0             |\n",
            "|-116.3_33.7|true     |93056.25                  |2.75870625           |3867.625           |2401.9375         |\n",
            "|-116.3_33.8|true     |67500.0                   |3.4583               |880.0              |507.0             |\n",
            "|-116.3_34.1|true     |65800.0                   |3.7292               |452.0              |184.0             |\n",
            "|-116.3_34.2|true     |42500.0                   |2.2083               |1175.0             |355.0             |\n",
            "|-116.3_36.0|true     |32900.0                   |1.1471               |1372.0             |436.0             |\n",
            "|-116.4_32.7|true     |110700.0                  |1.7137               |2595.0             |1046.0            |\n",
            "|-116.4_33.1|true     |98700.0                   |2.5795               |4890.0             |1289.0            |\n",
            "|-116.4_33.2|true     |100000.0                  |3.3625               |1791.0             |327.0             |\n",
            "|-116.4_33.3|true     |176400.0                  |3.3214               |2746.0             |731.0             |\n",
            "|-116.4_33.6|true     |168020.0                  |4.93424              |6372.4             |1782.0            |\n",
            "|-116.4_33.7|false    |200900.0                  |4.732937499999999    |11586.125          |2758.0            |\n",
            "|-116.4_33.8|true     |76450.0                   |2.25315              |11836.0            |3287.5            |\n",
            "|-116.4_34.0|true     |97800.0                   |3.2723               |4855.0             |2098.0            |\n",
            "|-116.4_34.1|true     |72237.5                   |2.2317125            |3200.0             |1403.5            |\n",
            "|-116.4_34.2|true     |65000.0                   |2.0674               |4985.0             |2517.0            |\n",
            "|-116.5_32.6|true     |127100.0                  |2.1949               |2680.0             |1644.0            |\n",
            "|-116.5_33.5|true     |103100.0                  |2.5625               |186.0              |102.0             |\n",
            "|-116.5_33.6|true     |167233.33333333334        |2.4625               |3333.0             |887.0             |\n",
            "|-116.5_33.7|false    |222772.81818181818        |3.9988181818181827   |5281.181818181818  |1187.6363636363637|\n",
            "|-116.5_33.8|true     |105433.33333333333        |3.2434               |5984.555555555556  |2691.6666666666665|\n",
            "|-116.5_33.9|true     |93520.0                   |2.49654              |4472.2             |1747.4            |\n",
            "|-116.5_34.0|true     |65300.0                   |1.9375               |5473.0             |2581.0            |\n",
            "|-116.5_34.1|true     |84833.33333333333         |2.3193333333333332   |4711.333333333333  |1895.0            |\n",
            "|-116.6_32.6|true     |116500.0                  |2.919                |4085.0             |2133.0            |\n",
            "|-116.6_32.9|true     |189900.0                  |4.57                 |4454.0             |1754.0            |\n",
            "|-116.6_33.0|true     |160550.0                  |3.45315              |1858.0             |574.0             |\n",
            "|-116.6_33.4|true     |113500.0                  |2.183                |3730.0             |1346.0            |\n",
            "|-116.6_33.6|true     |345500.0                  |6.2702               |489.0              |183.0             |\n",
            "|-116.6_33.7|true     |228050.0                  |3.2613000000000003   |5960.5             |1044.5            |\n",
            "|-116.6_33.8|true     |184900.07692307694        |3.1641384615384616   |6008.0             |1964.8461538461538|\n",
            "|-116.6_33.9|true     |66980.0                   |2.0767200000000003   |3148.8             |1447.8            |\n",
            "|-116.6_34.0|true     |73100.0                   |3.03065              |3594.0             |1318.5            |\n",
            "|-116.6_34.4|true     |51300.0                   |1.3811               |8502.0             |2330.0            |\n",
            "|-116.6_34.8|true     |64700.0                   |2.0                  |3149.0             |1281.0            |\n",
            "|-116.6_35.4|true     |22500.0                   |2.7138               |9975.0             |6835.0            |\n",
            "|-116.7_32.7|true     |240600.0                  |6.2152               |843.0              |918.0             |\n",
            "|-116.7_32.8|true     |169100.0                  |4.0159               |4115.0             |2032.0            |\n",
            "|-116.7_32.9|true     |193800.0                  |5.359                |349.0              |120.0             |\n",
            "+-----------+---------+--------------------------+---------------------+-------------------+------------------+\n",
            "only showing top 100 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "836ff541"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The top 10 spatial regions by median house value all have a value of \\$500,001.0, suggesting this is a capped value in the dataset.\n",
        "*   The distribution of median income varies across housing age buckets, with distinct differences in mean, standard deviation, minimum, and maximum income observed for each age range.\n",
        "*   The correlation between median income and median house value varies significantly across income buckets, being negative in the lowest income bucket (-0.1485) and strongly positive in the highest income bucket (0.5323).\n",
        "*   Outliers in the \"rooms per household\" ratio were successfully identified using the z-score method, indicating properties with exceptionally high or low room-to-household ratios.\n",
        "*   The average \"bedrooms per room\" ratio was calculated for each spatial region, providing insight into the composition of housing units across different areas.\n",
        "*   Population density (approximated as population per data point) was calculated for each spatial bin, showing the distribution of population across the binned grid.\n",
        "*   Analyzing year-to-year growth in median house value per region and temporal trends of income and house values over years could not be performed as the dataset lacks a 'year' column.\n",
        "*   Splitting house values into deciles revealed how average features like median income, total rooms, population, households, and housing median age vary across different house value ranges.\n",
        "*   Comparing younger (under 30 years) and older (30+ years) houses showed that older houses have a higher average price per room (\\$175.21) compared to younger houses (\\$132.37).\n",
        "*   Regression residual analysis identified specific areas (based on longitude and latitude) that the linear model predicted as potentially overvalued (largest positive residuals) or undervalued (largest negative residuals).\n",
        "*   The affordability index (average median income / average median house value) was computed for each spatial region.\n",
        "*   K-Means clustering on selected features successfully grouped properties into distinct clusters, with clear differences in average feature values observed for each cluster profile.\n",
        "*   The average house value difference between nearest neighboring blocks was calculated to be approximately \\$43,403.\n",
        "*   A moving average of median house values along longitude was computed, revealing spatial trends in house prices across the geographic range.\n",
        "*   Comparing house prices across population density buckets showed that the \"Medium\" density bucket has the highest average house value, followed by \"High\" and then \"Low\" density buckets.\n",
        "*   The Pearson correlation between Median House Value and Median Income (approx. 0.69) is significantly stronger than the correlation between Median House Value and Total Bedrooms (approx. 0.046), suggesting house value is more elastic with respect to income than total bedrooms.\n",
        "*   A histogram of housing median age showed the distribution of properties across defined age buckets (0-9, 10-19, etc.).\n",
        "*   The variance in house values was computed for each income decile, providing a measure of price dispersion within different income groups.\n",
        "*   A method was implemented to compare statistics (like average median house value) for border versus interior blocks within each spatial region, allowing for the detection and analysis of potential \"edge effects\".\n"
      ]
    }
  ]
}